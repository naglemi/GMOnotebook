{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6>*GMOdetector notebook* </font><br>\n",
    "**Template to analyze a new batch of images** (v.0.7.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workflow, images taken with the macroPhor Array dual RGB/hyperspectral imaging platform are analyzed by a workflow in which regression quantifies fluorescent signals in hyperspectral images, deep learning segments RGB images into different tissues, and these datasets are cross-referenced to produce statistics on growth of transgenic callus and shoot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment ID and description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Provide a short description of the experiment in the below box. This should include unique identifier codes for the experiment, along with a short description of genotypes and treatments studied. The timepoint should also be included. </div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset (Phase ID and week timepoint): \"ENTER_NOTE\"\n",
    "\n",
    "This notebook comes from a template which we use in R scripts to automatically generate a notebook for each \n",
    "transformation GWAS phase x timepoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "# Parameters for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "The below variables must be modified appropriately every time this workflow is run over new images.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data location\n",
    "The `data` variable below provides the **complete** path to the folder containing data to be analyzed. This should include all folders and subfolders in which the data of interest is organized by. For the organizational system used for our lab's data, this should follow the format \"/Experiment/Subexperiment/Timepoint/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"ENTER_DATA_PATH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample information\n",
    "Every experiment has a spreadsheet of metadata to organize treatment and genotype information for each plate, prepare labels, and randomize plates. [For details, see tutorial on preparing this spreadsheet](https://github.com/naglemi/GMOnotebook/blob/master/1_Decide_parameters/1_Metadata_and_randomization/1-Generate_randomization_scheme.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomization_datasheet=\"ENTER_RANDOMIZATION_DATASHEET_PATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=ENTER_GRID # 12 or 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection of missing or contaminated explants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the `missing_explants` variable to `\"Automatic\"` or to the path of manually prepared data file. [For details, see this tutorial and example file](https://github.com/naglemi/GMOnotebook/tree/master/1_Decide_parameters/3_Other_parameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Our automatic missing explant detection model is only trained for poplar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_explants=\"ENTER_DENSENET_OPTION_OR_SHEET\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation settings and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_mode=\"ENTER_SEGMENTATION_MODE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three below settings need to be changed if you wish to use a different model for hyperspectral segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_model_key=\"ENTER_HYP-SEGMENTATION_MODEL_KEY\"\n",
    "segmentation_model_path=\"ENTER_HYP-SEGMENTATION_MODEL_PATH\"\n",
    "segmentation_model_type=\"ENTER_HYP-SEGMENTATION_MODEL_TYPE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a list of classes that should not be included in the \"All regenerated tissues\" statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unregenerated_tissues=\"Background Stem Necrotic Explant\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing weights for fluorescent proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[See this notebook for details on all below fluorescent protein settings.](https://github.com/naglemi/GMOnotebook/blob/master/1_Decide_parameters/3_Other_parameters/3_Hyperspectral_settings.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL known fluorescent components in the sample should be included.\n",
    "# Library has DsRed, ZsYellow, GFP, Chl, ChlA, ChlB, Noise\n",
    "fluorophores=ENTER_FLUOROPHORES # Order doesn't matter here. Names must match library.\n",
    "desired_wavelength_range=ENTER_WAVELENGTHS # (first last), e.g. (500 900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing false-color plots for fluorescent proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FalseColor_channels=ENTER_CHANNELS # (Red Green Blue), e.g. (Chl GFP Noise)\n",
    "FalseColor_caps=ENTER_CAPS # (Red Green Blue); recommend 400 for reporters, 200 for others; e.g. (200 400 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing summary statistics for fluorescent proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporters=ENTER_REPORTERS # Will compute summary stats for these proteins, e.g. (GFP) or (GFP Chl)\n",
    "pixel_threshold=ENTER_PIXEL_THRESHOLD # If this many pixels... (recommended: 3)\n",
    "reporter_threshold=ENTER_REPORTER_THRESHOLD # ...have this much signal (recommended: 38), then the tissue is \"Positive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite=ENTER_COMPOSITE_OPTION # 1 to make composite images with side-by-side RGB, segmentation outputs and blended images (slow), 0 to skip\n",
    "width=ENTER_PLOT_WIDTH # GGplot box/violin plot output (inches)\n",
    "height=ENTER_PLOT_HEIGHT # GGplot box/violin plot output (inches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel=ENTER_PARALLEL_OPTION # 1 if parallelizing CubeGLM with GNU Parallel, 0 if not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths to workflow modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These only need to be modified if you are setting up a `GMOnotebook` template in a new environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmodetector_wd=\"/home/cubeglm/\"\n",
    "spectral_library_path=\"${gmodetector_wd}spectral_library/\"\n",
    "deeplab_path=\"/mnt/models/rgb/poplar_model_2_w_contam/\"\n",
    "densenet_model_path=\"/mnt/models/densenet_contamination/model_finetune.h5\"\n",
    "cubeml_path=\"/home/cubeml/\"\n",
    "alignment_path=\"/home/ImageAlignment/\"\n",
    "gmolabeler_path=\"/home/GMOlabeler/\"\n",
    "contamination_path=\"/home/DenseNet\"\n",
    "data_prefix=\"/mnt/output/\"\n",
    "output_directory_prefix=\"${data_prefix}gmodetector_out/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd=\"/home/GMOnotebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "With all above variables set, please \"Save as...\" with a filename referencing this specific dataset. <br>Finally, deploy the workflow (Step 4 in above instructions).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if inputs are OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will print warnings for any common problems that are detected with input variables we set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo ${fluorophores[@]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $fluorophores[@]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFS=','  # Setting the Internal Field Separator to ',' for array joining\n",
    "\n",
    "echo \"opt\\$data <- \\\"$data\\\"\"\n",
    "echo \"opt\\$randomization_datasheet <- \\\"$randomization_datasheet\\\"\"\n",
    "echo \"opt\\$segmentation_mode <- \\\"$segmentation_mode\\\"\"\n",
    "echo \"opt\\$unregenerated_tissues <- \\\"$unregenerated_tissues\\\"\"\n",
    "echo \"opt\\$grid <- \\\"$grid\\\"\"\n",
    "echo \"opt\\$missing_explants <- \\\"$missing_explants\\\"\"\n",
    "echo \"opt\\$fluorophores <- \\\"${fluorophores[*]}\\\"\"  # Joining array elements with IFS\n",
    "echo \"opt\\$desired_wavelength_range <- \\\"${desired_wavelength_range[*]}\\\"\"  # Joining array elements with IFS\n",
    "echo \"opt\\$FalseColor_channels <- \\\"${FalseColor_channels[*]}\\\"\"  # Joining array elements with IFS\n",
    "echo \"opt\\$FalseColor_caps <- \\\"${FalseColor_caps[*]}\\\"\"  # Joining array elements with IFS\n",
    "echo \"opt\\$reporters <- \\\"${reporters[*]}\\\"\"  # Joining array elements with IFS\n",
    "echo \"opt\\$pixel_threshold <- \\\"$pixel_threshold\\\"\"\n",
    "echo \"opt\\$reporter_threshold <- \\\"$reporter_threshold\\\"\"\n",
    "echo \"opt\\$segmentation_model_key <- \\\"$segmentation_model_key\\\"\"\n",
    "echo \"opt\\$segmentation_model_path <- \\\"$segmentation_model_path\\\"\"\n",
    "echo \"opt\\$gmodetector_wd <- \\\"$gmodetector_wd\\\"\"\n",
    "echo \"opt\\$spectral_library_path <- \\\"$spectral_library_path\\\"\"\n",
    "echo \"opt\\$deeplab_path <- \\\"$deeplab_path\\\"\"\n",
    "echo \"opt\\$cubeml_path <- \\\"$cubeml_path\\\"\"\n",
    "echo \"opt\\$alignment_path <- \\\"$alignment_path\\\"\"\n",
    "echo \"opt\\$gmolabeler_path <- \\\"$gmolabeler_path\\\"\"\n",
    "echo \"opt\\$contamination_path <- \\\"$contamination_path\\\"\"\n",
    "echo \"opt\\$data_prefix <- \\\"$data_prefix\\\"\"\n",
    "echo \"opt\\$output_directory_prefix <- \\\"$output_directory_prefix\\\"\"\n",
    "echo \"opt\\$cwd <- \\\"$cwd\\\"\"\n",
    "\n",
    "unset IFS  # Resetting IFS back to default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rscript ${cwd}/intermediates/are_inputs_ok.R \\\n",
    "  --data \"$data\" \\\n",
    "  --randomization_datasheet \"$randomization_datasheet\" \\\n",
    "  --segmentation_mode \"$segmentation_mode\" \\\n",
    "  --unregenerated_tissues \"$unregenerated_tissues\" \\\n",
    "  --grid \"$grid\" \\\n",
    "  --missing_explants \"$missing_explants\" \\\n",
    "  --fluorophores \"$(IFS=,; echo \"${fluorophores[*]}\")\" \\\n",
    "  --desired_wavelength_range \"$(IFS=,; echo \"${desired_wavelength_range[*]}\")\" \\\n",
    "  --FalseColor_channels \"$(IFS=,; echo \"${FalseColor_channels[*]}\")\" \\\n",
    "  --FalseColor_caps \"$(IFS=,; echo \"${FalseColor_caps[*]}\")\" \\\n",
    "  --reporters \"$(IFS=,; echo \"${reporters[*]}\")\" \\\n",
    "  --pixel_threshold \"$pixel_threshold\" \\\n",
    "  --reporter_threshold \"$reporter_threshold\" \\\n",
    "  --segmentation_model_key \"$segmentation_model_key\" \\\n",
    "  --segmentation_model_path \"$segmentation_model_path\" \\\n",
    "  --gmodetector_wd \"$gmodetector_wd\" \\\n",
    "  --spectral_library_path \"$spectral_library_path\" \\\n",
    "  --deeplab_path \"$deeplab_path\" \\\n",
    "  --cubeml_path \"$cubeml_path\" \\\n",
    "  --alignment_path \"$alignment_path\" \\\n",
    "  --gmolabeler_path \"$gmolabeler_path\" \\\n",
    "  --contamination_path \"$contamination_path\" \\\n",
    "  --data_prefix \"$data_prefix\" \\\n",
    "  --output_directory_prefix \"$output_directory_prefix\" \\\n",
    "  --cwd \"$cwd\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated workflow to be deployed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the below code for a walkthrough of how GMOnotebook works, or view the outputs after running the workflow for help troubleshooting errors in specific steps of analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> <b>Danger:</b> Do not modify any below code without creating a new version of the template notebook. During routine usage, this workflow should be customized only by modifying variables above, while leaving the below code unmodified. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These internal variables are set automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datestamp=$(date +”%Y-%m-%d”)\n",
    "data_folder=$(echo $data | cut -d/ -f5-)\n",
    "timepoint=\"$(basename -- $data_folder)\"\n",
    "output_directory_full=\"$output_directory_prefix$data_folder\"\n",
    "dataset_name=$(echo $data_folder | sed -e 's/\\///g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ \"$segmentation_mode\" = \"rgb\" ]; then\n",
    "    unset segmentation_model_key\n",
    "    unset segmentation_model_path\n",
    "    unset segmentation_model_type\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time analysis begins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantification of fluorescent proteins by regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python package `CubeGLM` is used to quantify fluorescent proteins in each pixel of hyperspectral images via linear regression. Hyperspectral images are regressed over spectra of known components, and pixelwise maps of test-statistics are constructed for each component in the sample. This approach to quantifying components of hyperspectral images is described in-depth in the Methods section from <a href=\"https://link.springer.com/article/10.1007/s40789-019-0252-7\" target=\"_blank\">Böhme, et al. 2019</a>. Code and documentation for `CubeGLM` is on <a href=\"https://github.com/naglemi/GMOdetector_py\" target=\"_blank\">Github</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $data_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_list_name=\"$dataset_name.jobs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf $job_list_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in $data/*.hdr\n",
    "do\n",
    " if [[ \"$file\" != *'roadband'* ]]; then\n",
    "  echo \"python -W ignore ${gmodetector_wd}/wrappers/analyze_sample.py \\\n",
    "--file_path $file \\\n",
    "--fluorophores ${fluorophores[*]} \\\n",
    "--min_desired_wavelength ${desired_wavelength_range[0]} \\\n",
    "--max_desired_wavelength ${desired_wavelength_range[1]} \\\n",
    "--red_channel ${FalseColor_channels[0]} \\\n",
    "--green_channel ${FalseColor_channels[1]} \\\n",
    "--blue_channel ${FalseColor_channels[2]} \\\n",
    "--red_cap ${FalseColor_caps[0]} \\\n",
    "--green_cap ${FalseColor_caps[1]} \\\n",
    "--blue_cap ${FalseColor_caps[2]} \\\n",
    "--plot 1 \\\n",
    "--spectral_library_path \"$spectral_library_path\" \\\n",
    "--output_dir $output_directory_full \\\n",
    "--threshold 38\" >> $job_list_name\n",
    " fi\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if [ $parallel -eq 1 ]\n",
    "then\n",
    "    parallel --jobs 20 -a $job_list_name\n",
    "fi\n",
    "\n",
    "if [ $parallel -eq 0 ]\n",
    "then\n",
    "    bash $job_list_name\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time regression completes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine borders of grid in hyperspectral image, which we'll use for alignment and/or cropping to explants later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection of grid edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to process orientation and extract grid borders\n",
    "process_orientation() {\n",
    "    local mode=$1\n",
    "    local rotation=$2\n",
    "    local flip_horizontal=$3\n",
    "    local label=$4\n",
    "    local half_scale=$5\n",
    "\n",
    "    # Navigate to the intermediates directory and run the Python script\n",
    "    cd \"${cwd}/intermediates/\"\n",
    "    command=\"python3.8 find_grid_position.py --mode $mode --cap 500 --index 130 --data $data --plot --rotation $rotation\"\n",
    "    #command=\"python3.8 ${cwd}/intermediates/find_grid_position.py --mode $mode --cap 500 --index 130 --data $data --plot --rotation $rotation\"\n",
    "    if [ \"$flip_horizontal\" = true ]; then\n",
    "        command=\"$command --flip_horizontal\"\n",
    "    fi\n",
    "    eval $command\n",
    "\n",
    "    # Navigate to the data directory where coordinates.csv is saved\n",
    "    cd \"$data\"\n",
    "    cat coordinates.csv\n",
    "\n",
    "    # Read the CSV file and extract x1, x2, y1, y2\n",
    "    firstline=1\n",
    "    while IFS=',' read -r mode x1 x2 y1 y2; do\n",
    "        if [ \"$firstline\" -eq \"0\" ]; then\n",
    "            if [ \"$half_scale\" = true ]; then\n",
    "                # Divide by 2 and round to integer\n",
    "                x1=$(printf \"%.0f\" $(echo \"$x1 / 2\" | bc -l))\n",
    "                x2=$(printf \"%.0f\" $(echo \"$x2 / 2\" | bc -l))\n",
    "                y1=$(printf \"%.0f\" $(echo \"$y1 / 2\" | bc -l))\n",
    "                y2=$(printf \"%.0f\" $(echo \"$y2 / 2\" | bc -l))\n",
    "            fi\n",
    "            eval \"$label=\\\"$x1,$y1,$x2,$y2\\\"\"\n",
    "        fi\n",
    "        firstline=0\n",
    "    done < coordinates.csv\n",
    "}\n",
    "\n",
    "# Process original orientation\n",
    "process_orientation \"hyperspectral\" 0 false \"aligned_grid_borders_original\" false\n",
    "\n",
    "# Process label bottom orientation\n",
    "process_orientation \"hyperspectral\" 270 true \"aligned_grid_borders_label_bottom\" false\n",
    "\n",
    "# Process for DenseNet model orientation\n",
    "process_orientation \"RGB\" 270 false \"pre_aligned_resized_grid_borders_densenet\" true\n",
    "\n",
    "# Process for hyperspectral layer matching orientation\n",
    "process_orientation \"RGB\" 180 true \"pre_aligned_grid_borders_hyp_oriented\" false\n",
    "\n",
    "\n",
    "# Print results\n",
    "echo \"Hyperspectral, original orientation:      $aligned_grid_borders_original\"\n",
    "echo \"Hyperspectral, transf. for labels on bot: $aligned_grid_borders_label_bottom\"\n",
    "echo \"RGB, rotated and scaled for Densenet:     $pre_aligned_resized_grid_borders_densenet\"\n",
    "echo \"RGB, oriented for alignment with hyp:     $pre_aligned_grid_borders_hyp_oriented\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic segmentation of tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are segmented into specific plant tissues by a deep neural network of the state-of-the-art Deeplab v3 architecture <a href=\"https://arxiv.org/abs/1706.05587\" target=\"_blank\">Liang-Chieh et al., 2017</a>. The model has been trained using training sets generated with our annotation GUI Intelligent DEep Annotator for Segmentation (IDEAS, available on <a href=\"https://bitbucket.org/JialinYuan/image-annotator/src/master/\" target=\"_blank\">Bitbucket</a>, publication pending). Our branch of the Deeplab v3 repo, including a Jupyter walkthrough for training, can be found on Github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is completed upstream of this notebook, which only entails analysis of test data using the latest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/downsized/segmentation_composite2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: This example image was taken from an experiment on the effects of different CIMs on cottonwood regeneration. This composite image illustrates that for every sample, tissues are segmented into stem (red), callus (blue) and shoot (green). These composite images, useful for manual inspection of results, are produced when the 'composite' option is on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We desire for images to all be in the same orientation. At one point, the camera on the *macroPhor Array* was set to automatically detect orientation, which led to images randomly being in portrait or landscape. Here we will standardize the orientation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for filename in $data/*.jpg; do\n",
    "    exiftool -Orientation=8 -n $filename > ${data}log_exiftool.txt\n",
    "    done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -f $data/*original*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crop and resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script resizes images to 900x900 and then crops away top and bottom 150 pixels for a final image size of 900x600."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose for cropping is to remove labels, which has been standard practice for all training and testing. Otherwise, we could run into problems such as the neural network \"learning\" plants labeled as control have more or less regeneration.<br>The purpose for resizing is to reduce computational expense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ \"$segmentation_mode\" = \"rgb\" ]; then\n",
    "    cd ${cwd}/intermediates/\n",
    "    python crop.py $data\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare input list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script `inference.py` requires a list of all files to be analyzed. We will create this file as `test.csv`. This will be a list of all our (pre-processed) image files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ \"$segmentation_mode\" = \"rgb\" ]; then\n",
    "    cd $data\n",
    "    ls -d $PWD/* $data | grep -i \"rgb_cropped.jpg\" > test.csv\n",
    "    sed -i '/hroma/d' \"${data}/test.csv\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model is deployed to perform semantic segmentation of experimental images. A list of RGB images to be segmented by the trained model is passed through the --image-list option. For each of these images, we will obtain an output mask (.png) of labeled tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies include `opencv`, `scipy`, `yaml` and `tensorflow` (version 1.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if [ \"$segmentation_mode\" = \"rgb\" ]; then\n",
    "    export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim\n",
    "    cd $deeplab_path\n",
    "    python3.7 -W ignore deeplab/inference.py \\\n",
    "        --image_lists \"${data}/test.csv\" \\\n",
    "        --crop_size 900 --crop_size 600 \\\n",
    "        --seg_results segmentation_results \\\n",
    "        --model_dir \"${deeplab_path}/deeplab/model/\" \\\n",
    "        >> $data/log_inference.txt\n",
    "    mv \"${deeplab_path}/segmentation_results/raw/\"* $data/\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if [ \"$segmentation_mode\" = \"hyperspectral\" ]; then\n",
    "    cd $cubeml_path\n",
    "    #cd /mnt/cubeml/\n",
    "    python scripts/batch_inference.py \\\n",
    "    --dir $data \\\n",
    "    --pickle $segmentation_model_path \\\n",
    "    --method $segmentation_model_type \\\n",
    "    --false_color\n",
    "    >> $data/log_inference.txt\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name outputs to reflect that they are segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ \"$segmentation_mode\" = \"rgb\" ]; then\n",
    "    cd $data\n",
    "    for file in *_rgb_cropped.png; do mv -f \"$file\" \"${file%_rgb_cropped.png}_segment_cropped.png\"; done\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-expand segment outputs to same size as original RGB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ \"$segmentation_mode\" = \"rgb\" ]; then\n",
    "    cd $alignment_path\n",
    "    python expand.py $data >> $data/log_expand.txt\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make composite images with side-by-side RGB, segmentation outputs and blended images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ $composite -eq 1 ]\n",
    "then\n",
    "    echo \"making composites\"\n",
    "    cd $gmolabeler_path\n",
    "    python image_blender.py $data 0.75 'both' 1 0\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of contaminated/missing explants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plates are cropped into sub-images for each explant and each is analyzed to determine if the explant position should be excluded from analysis due to being missing or contamination. Missing and contaminated explants are recognized using a trained Densenet model (<a href=\"https://github.com/Contamination-Classification/DenseNet\" target=\"_blank\">Huang, et al. 2018</a>). Our fork of the Densenet repository is available on <a href=\"https://arxiv.org/abs/1608.06993\" target=\"_blank\">GitHub</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/Densenet.png\">\n",
    "Figure: These are four examples of contaminated explants used in the training set for this pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the grid cropping dimensions, we can run the following script. Note that these are the dimensions to crop the image to after resizing to 2000x2000 (from 4000x4000 in the case of the *macroPhor Array*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare list of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ $missing_explants = \"Automatic\" ]; then\n",
    "   echo \"Missing explants will be inferred.\"\n",
    "   cd $data\n",
    "   ls -d $PWD/* $data | grep -i \"rgb.jpg\" > rgb_list.txt\n",
    "   sed -i '/hroma/d' rgb_list.txt\n",
    "   img_list_path=\"${data}/rgb_list.txt\"\n",
    "else\n",
    "   echo \"Missing explants input manually by user, in file: \"\n",
    "   echo $missing_explants\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the mode for missing explant data is automatic, prepare input file for script to detect missing explants and run this script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer contaminated/missing explants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "if [ $missing_explants = \"Automatic\" ]; then\n",
    "    cd $data\n",
    "    python3.7 -W ignore ${contamination_path}/inference.py \\\n",
    "    --img-list=$img_list_path \\\n",
    "    --crop_dims $pre_aligned_resized_grid_borders_densenet \\\n",
    "    --weights_path $densenet_model_path \\\n",
    "    --output_file=\"${data}/output.csv\" >> $data/log_contam.txt\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ $missing_explants = \"Automatic\" ]; then\n",
    "    missing_explants=\"${data}/output.csv\"\n",
    "    echo \"Missing explants inferred by model and written to file:\"\n",
    "    echo $missing_explants\n",
    "else\n",
    "    echo \"Missing explants input manually by user, in file: \"\n",
    "    echo $missing_explants\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment of RGB and hyperspectral layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match the frame and angle of RGB and hyperspectral image layers, we perform a homography transformation using a method described [in these notebooks](https://github.com/naglemi/GMOnotebook/tree/master/1_Decide_parameters/2_Align_and_crop_parameters/2_find_alignment_parameters). Using a pair of standard images, a homography matrix is calculated for the necessary transformation of RGB images to align with hyperspectral images. The transformation can then be applied to large batches of images rapidly, as long as the RGB and hyperspectral cameras remain in the same positions relative to one another (as they do in the macroPhor Array platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/Alignment.png\">\n",
    "Figure: To enable precise calculation of a homography matrix for transformation of RGB images to match hyperspectral images, we used images of a piece of paper with grid marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"Original Borders: $aligned_grid_borders_original\"\n",
    "echo \"Label Bottom Borders: $aligned_grid_borders_label_bottom\"\n",
    "echo \"DenseNet Borders: $pre_aligned_resized_grid_borders_densenet\"\n",
    "echo \"Hyperspectral Oriented Borders: $pre_aligned_grid_borders_hyp_oriented\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assuming that the borders are provided as four integers each, in the order: left, top, right, bottom\n",
    "pre_aligned_borders=(${pre_aligned_grid_borders_hyp_oriented//,/ })\n",
    "aligned_borders=(${aligned_grid_borders_original//,/ })\n",
    "\n",
    "# Call the new script with these borders and other necessary arguments\n",
    "#if [ \"$segmentation_mode\" = \"rgb\" ]; then\n",
    "python3.8 ${cwd}/intermediates/batch_align_auto.py \\\n",
    "--left_source ${pre_aligned_borders[0]} \\\n",
    "--top_source ${pre_aligned_borders[1]} \\\n",
    "--right_source ${pre_aligned_borders[2]} \\\n",
    "--bottom_source ${pre_aligned_borders[3]} \\\n",
    "--left_target ${aligned_borders[0]} \\\n",
    "--top_target ${aligned_borders[1]} \\\n",
    "--right_target ${aligned_borders[2]} \\\n",
    "--bottom_target ${aligned_borders[3]} \\\n",
    "--img_dir $data \\\n",
    "--hyp_path $output_directory_full \\\n",
    "--channel_index 130 \\\n",
    "--overlay_dir \"/mnt/output/debug/\"\n",
    "#fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ \"$segmentation_mode\" = \"rgb\" ]; then\n",
    "    hypercube_jpg=$(echo $hypercube_csv | sed -e 's/\\.csv/.jpg/g')\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-analyze deep segmentation and regression results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripts in the <a href=\"https://github.com/naglemi/GMOlabeler\" target=\"_blank\">GMOlabeler repository</a> are used to cross-reference results from deep segmentation of RGB images and regression of hyperspectral imaging, apply thresholding parameters to classify tissues as transgenic or escapes, and produce plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/GMOlabeler.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: The various steps of data processing in GMOlabeler are illustrated for an example explant from an experiment on CIM optimization for cottonwood. Images of plates are cropped to a sub-image for each explant. RGB segmentation results and hyperspectral regression results are cross-referenced to calculate fluorecent proteins in specific tissues and infer whether these tissues are transgenic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare sample datasheet input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input file we will use for making plots. This file contains paths to CLS results, RGB images, and hyperspectral images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $datestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd \"${cwd}/intermediates/\"\n",
    "\n",
    "# Check if segmentation_mode is set to \"hyperspectral\"\n",
    "if [ \"$segmentation_mode\" = \"hyperspectral\" ]; then\n",
    "  Rscript pre_label.R \\\n",
    "  -r \"${data}/\" \\\n",
    "  -R \"${output_directory_prefix}\" \\\n",
    "  -i 1 \\\n",
    "  -d $datestamp \\\n",
    "  --segmentation_model_key $segmentation_model_key # Only included if segmentation_mode is hyperspectral\n",
    "else\n",
    "  Rscript pre_label.R \\\n",
    "  -r \"${data}/\" \\\n",
    "  -R \"${output_directory_prefix}\" \\\n",
    "  -i 1 \\\n",
    "  -d $datestamp\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if $aligned_grid is unset or the file doesn't exist\n",
    "if [[ -z \"$aligned_grid\" || ! -f \"$aligned_grid\" ]]; then\n",
    "  echo \"No grid found at a path given by user, searching for one...\"\n",
    "\n",
    "  # Find files, extract filenames and timestamps, sort by timestamp, and get the filename with the second-to-last timestamp\n",
    "  #  in Strauss Lab, this will always represent the grid with bold numbers and lines, useful for visualizing grid cropping\n",
    "  aligned_grid=$(find \"$data\" -maxdepth 1 -type f -name \"*hroma*rgb_processed.png*\" ! -name \"*csv*\" \\\n",
    "                 | while read -r file; do\n",
    "                     timestamp=$(echo \"$file\" | grep -o '[0-9]\\{6\\}')\n",
    "                     echo \"$timestamp $file\"\n",
    "                   done \\\n",
    "                 | sort -k1,1nr \\\n",
    "                 | head -n 2 \\\n",
    "                 | tail -n 1 \\\n",
    "                 | cut -d' ' -f2-)\n",
    "\n",
    "  # Check if a file was found\n",
    "  if [[ -z \"$aligned_grid\" ]]; then\n",
    "    echo \"No suitable grid file found.\"\n",
    "  else\n",
    "    # Output the found path\n",
    "    echo \"Grid found: $aligned_grid\"\n",
    "  fi\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $aligned_grid_borders_label_bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo ${data}/samples_pre_labeling.csv\n",
    "echo $aligned_grid\n",
    "echo $reporter_threshold\n",
    "echo \"Chl\"\n",
    "echo $grid\n",
    "echo \"hdf\"\n",
    "echo ${output_directory_prefix}/gmolabeler_logic_outputs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_grid_borders_label_bottom_formatted=$(echo $aligned_grid_borders_original | awk -F',' '{print $2, $4, $3, $1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $aligned_grid_borders_label_bottom_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_grid_borders_label_bottom_formatted=$(echo $aligned_grid_borders_original | awk -F',' '{print $2, $4, $3, $1}')\n",
    "cd $gmolabeler_path\n",
    "for reporter in ${reporters[@]}; do\n",
    "    # Start the command with the basic arguments\n",
    "    cmd=\"python main.py \\\n",
    "    \\\"${data}/samples_pre_labeling.csv\\\" \\\n",
    "    $aligned_grid \\\n",
    "    $reporter_threshold \\\n",
    "    $reporter \\\n",
    "    $grid \\\n",
    "    \\\"hdf\\\" \\\n",
    "    \\\"${output_directory_prefix}/gmolabeler_logic_outputs/\\\"\"\n",
    "\n",
    "    # Append the grid borders to the command\n",
    "    if [[ -n \"$aligned_grid_borders_label_bottom_formatted\" ]]; then\n",
    "        cmd+=\" \\\"$aligned_grid_borders_label_bottom_formatted\\\"\"\n",
    "    fi\n",
    "\n",
    "    # Check if segmentation_model_key is set and points to a file\n",
    "    if [[ -n $segmentation_model_key && -f $segmentation_model_key ]]; then\n",
    "        # Append the segmentation model key to the command as a named argument\n",
    "        cmd+=\" --segmentation_model_key \\\"$segmentation_model_key\\\"\"\n",
    "    fi\n",
    "\n",
    "    # Run the command and redirect stdout to the log file\n",
    "    eval $cmd > \"$data/log_gmolabeler_$reporter.txt\"\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate sums of statistics over combined segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in all regenerated tissue (callus + shoot) as well as all tissue (including stem as well). We will calculate aggregate statistics over these groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $segmentation_model_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $gmolabeler_path\n",
    "for reporter in \"${reporters[@]}\"; do\n",
    "    # Start the command with the base part\n",
    "    cmd=\"Rscript calculate_sum_stats_over_combined_segments.R \\\n",
    "    --output_dir \\\"${output_directory_prefix}/gmolabeler_logic_outputs/\\\" \\\n",
    "    --datapath \\\"${data_folder}/${reporter}/\\\"\"\n",
    "\n",
    "    # Append the model key path if it's set and not None\n",
    "    if [ -n \"${segmentation_model_key}\" ] && [ \"${segmentation_model_key}\" != \"None\" ]; then\n",
    "        cmd+=\" --keypath \\\"${segmentation_model_key}\\\"\"\n",
    "    fi\n",
    "\n",
    "    # Append the exclude tissues string if it's set and not None\n",
    "    if [ -n \"${unregenerated_tissues}\" ] && [ \"${unregenerated_tissues}\" != \"None\" ]; then\n",
    "        echo $exclude_tissues\n",
    "        cmd+=\" --exclude_tissues \\\"${unregenerated_tissues}\\\"\"\n",
    "    fi\n",
    "    \n",
    "    echo $cmd\n",
    "\n",
    "    # Execute the command\n",
    "    eval $cmd\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make plots of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cd $gmolabeler_path\n",
    "for reporter in ${reporters[@]}; do\n",
    "    # Start the command with the base part\n",
    "    cmd=\"Rscript grid_item_plots.R \\\n",
    "    -d \\\"${data_folder}/\\\" \\\n",
    "    -r \\\"$randomization_datasheet\\\" \\\n",
    "    -p $pixel_threshold \\\n",
    "    -v categorical \\\n",
    "    -m 1 \\\n",
    "    -M $missing_explants \\\n",
    "    -g $grid \\\n",
    "    --samples-pre-labeling ${data}/samples_pre_labeling.csv \\\n",
    "    --sort 1 \\\n",
    "    --height $height \\\n",
    "    --width $width \\\n",
    "    --Reporter $reporter \\\n",
    "    --outdir \\\"${output_directory_prefix}\\\"\"\n",
    "\n",
    "    # Append the model key path if it's set and not None\n",
    "    if [ -n \"$segmentation_model_key\" ] && [ \"$segmentation_model_key\" != \"None\" ]; then\n",
    "        cmd+=\" --keypath \\\"$segmentation_model_key\\\"\"\n",
    "    fi\n",
    "\n",
    "    echo $cmd\n",
    "\n",
    "    # Execute the command\n",
    "    eval $cmd\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo -e \"Complete \\u2705\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

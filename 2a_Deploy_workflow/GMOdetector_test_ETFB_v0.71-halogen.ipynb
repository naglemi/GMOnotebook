{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6>*GMOdetector notebook*: Template to analyze a new batch of images</font><br>\n",
    "**Notebook template for applying routine hyperspectral/segmentation cross-analysis phenomics workflow over new datasets** (v.0.6.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"Figures/WorkflowFlowchart.png\" width = 500>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workflow, images taken with the macroPhor Array dual RGB/hyperspectral imaging platform are analyzed by a workflow in which regression quantifies fluorescent signals in hyperspectral images, deep learning segments RGB images into different tissues, and these datasets are cross-referenced to produce statistics on growth of transgenic callus and shoot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment ID and description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Provide a short description of the experiment in the below box. This should include unique identifier codes for the experiment, along with a short description of genotypes and treatments studied. The timepoint should also be included. </div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset (Phase ID and week timepoint): \"ENTER_NOTE\"\n",
    "\n",
    "This notebook comes from a template which we use in R scripts to automatically generate a notebook for each \n",
    "transformation GWAS phase x timepoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "# Parameters for analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "The below variables must be modified appropriately every time this workflow is run over new images.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data location\n",
    "The `data` variable below provides the **complete** path to the folder containing data to be analyzed. This should include all folders and subfolders in which the data of interest is organized by. For the organizational system used for our lab's data, this should follow the format \"/Experiment/Subexperiment/Timepoint/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "data=\"/mnt/Elements_24/EUC_transformation/ETFB/wk26/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample information\n",
    "Every experiment has a spreadsheet of metadata to organize treatment and genotype information for each plate, prepare labels, and randomize plates. [For details, see tutorial on preparing this spreadsheet](https://github.com/naglemi/GMOnotebook/blob/master/1_Decide_parameters/1_Metadata_and_randomization/1-Generate_randomization_scheme.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "randomization_datasheet=\"/mnt/Elements_24/EUC_transformation/ETFB/ETFB_rand_labels.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "segmentation_mode=\"hyperspectral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "unregenerated_tissues=\"Background Explant Necrotic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection of missing or contaminated explants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the `missing_explants` variable to `\"Automatic\"` or to the path of manually prepared data file. [For details, see this tutorial and example file](https://github.com/naglemi/GMOnotebook/tree/master/1_Decide_parameters/3_Other_parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "missing_explants=\"Automatic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluorescent protein settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing weights for fluorescent proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[See this notebook for details on all below fluorescent protein settings.](https://github.com/naglemi/GMOnotebook/blob/master/1_Decide_parameters/3_Other_parameters/3_Hyperspectral_settings.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h\u001b[?2004l\u001b[?2004l\u001b[?2004l"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# ALL known fluorescent components in the sample should be included.\n",
    "# Library has DsRed, ZsYellow, GFP, Chl, ChlA, ChlB, Noise\n",
    "fluorophores=(DsRed Chl Noise) # Order doesn't matter here. Names must match library.\n",
    "desired_wavelength_range=(500 900) # (first last), e.g. (500 900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing false-color plots for fluorescent proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h\u001b[?2004l"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "FalseColor_channels=(Chl DsRed Noise) # (Red Green Blue), e.g. (Chl GFP Noise)\n",
    "FalseColor_caps=(200 200 200) # (Red Green Blue); recommend 400 for reporters, 200 for others; e.g. (200 400 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing summary statistics for fluorescent proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h\u001b[?2004l\u001b[?2004l"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "reporters=(DsRed Chl) # Will compute summary stats for these proteins, e.g. (GFP) or (GFP Chl)\n",
    "pixel_threshold=3 # If this many pixels... (recommended: 3)\n",
    "reporter_threshold=38 # ...have this much signal (recommended: 38), then the tissue is \"Positive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping and alignment settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings and files for cropping to grid spots and aligning RGB/hyperspectral layers should be prepared according to [these tutorials](https://github.com/naglemi/GMOnotebook/tree/master/1_Decide_parameters/2_Align_and_crop_parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "grid=12 # 12 or 20\n",
    "pre_aligned_resized_grid_borders=(\"Automatic\") # \"(left,top,right,bottom)\"\n",
    "aligned_grid_borders=\"Automatic\" # \"top bottom right left\"\n",
    "mode=\"scikit\" # \"scikit\" (recommended) or \"opencv\"\n",
    "homography=\"ENTER_HOMOGRAPHY_NPY\" # file path\n",
    "hypercube_csv=\"ENTER_HYPERCUBE_TO_CSV\" # file path\n",
    "aligned_grid=\"ENTER_ALIGNED_GRID\" # file path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h\u001b[?2004l\u001b[?2004l\u001b[?2004l"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "composite=0 # 1 to make composite images with side-by-side RGB, segmentation outputs and blended images (slow), 0 to skip\n",
    "test_align_each_img=0 # 1 to make blended images of aligned RGB and hyperspectral layers for inspection, 0 to skip\n",
    "width=9 # GGplot box/violin plot output (inches)\n",
    "height=5 # GGplot box/violin plot output (inches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "parallel=0 # 1 if parallelizing CubeGLM with GNU Parallel, 0 if not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths to workflow modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These only need to be modified if you are setting up a `GMOnotebook` template on a new computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cwd=\"/home/GMOnotebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "gmodetector_wd=\"/home/cubeglm/\"\n",
    "spectral_library_path=\"${gmodetector_wd}spectral_library/\"\n",
    "#deeplab_path=\"/home/gmobot/poplar_model_2_w_contam/\"\n",
    "cubeml_path=\"/home/cubeml/\"\n",
    "segmentation_model_path=\"/home/euc_cubeschool_a1-v4_cpua2.pkl\"\n",
    "alignment_path=\"/home/ImageAlignment/\"\n",
    "gmolabeler_path=\"/home/GMOlabeler/\"\n",
    "contamination_path=\"/home/DenseNet\"\n",
    "data_prefix=\"/mnt/output/\"\n",
    "output_directory_prefix=\"${data_prefix}gmodetector_out/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "With all above variables set, please \"Save as...\" with a filename referencing this specific dataset. <br>Finally, deploy the workflow (Step 4 in above instructions).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "segmentation_model_key=$(echo $segmentation_model_path | sed 's/.pkl$/.key.csv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",Tissue,hex_code,Integer\n",
      "0,Background,#000000,0\n",
      "1,Callus,#0000FF,1\n",
      "2,Necrotic,#964B00,2\n",
      "3,Explant,#FF0000,3\n",
      "4,Shoot,#AADB1E,4\n",
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cat $segmentation_model_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated workflow to be deployed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the below code for a walkthrough of how GMOnotebook works, or view the outputs after running the workflow for help troubleshooting errors in specific steps of analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> <b>Danger:</b> Do not modify any below code without creating a new version of the template notebook. During routine usage, this workflow should be customized only by modifying variables above, while leaving the below code unmodified. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These internal variables are set automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "datestamp=$(date +”%Y-%m-%d”)\n",
    "data_folder=$(echo $data | cut -d/ -f5-)\n",
    "timepoint=\"$(basename -- $data_folder)\"\n",
    "output_directory_full=\"$output_directory_prefix$data_folder\"\n",
    "dataset_name=$(echo $data_folder | sed -e 's/\\///g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time analysis begins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 24 23:25:31 PST 2023\n",
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "echo $(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantification of fluorescent proteins by regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python package `CubeGLM` is used to quantify fluorescent proteins in each pixel of hyperspectral images via linear regression. Hyperspectral images are regressed over spectra of known components, and pixelwise maps of test-statistics are constructed for each component in the sample. This approach to quantifying components of hyperspectral images is described in-depth in the Methods section from <a href=\"https://link.springer.com/article/10.1007/s40789-019-0252-7\" target=\"_blank\">Böhme, et al. 2019</a>. Code and documentation for `CubeGLM` is on <a href=\"https://github.com/naglemi/GMOdetector_py\" target=\"_blank\">Github</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cd $data_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "job_list_name=\"$dataset_name.jobs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "rm -rf $job_list_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "for file in $data/*.hdr\n",
    "do\n",
    " if [[ \"$file\" != *'hroma'* ]] && [[ \"$file\" != *'roadband'* ]]; then\n",
    "  echo \"python -W ignore ${gmodetector_wd}/wrappers/analyze_sample.py \\\n",
    "--file_path $file \\\n",
    "--fluorophores ${fluorophores[*]} \\\n",
    "--min_desired_wavelength ${desired_wavelength_range[0]} \\\n",
    "--max_desired_wavelength ${desired_wavelength_range[1]} \\\n",
    "--red_channel ${FalseColor_channels[0]} \\\n",
    "--green_channel ${FalseColor_channels[1]} \\\n",
    "--blue_channel ${FalseColor_channels[2]} \\\n",
    "--red_cap ${FalseColor_caps[0]} \\\n",
    "--green_cap ${FalseColor_caps[1]} \\\n",
    "--blue_cap ${FalseColor_caps[2]} \\\n",
    "--plot 1 \\\n",
    "--spectral_library_path \"$spectral_library_path\" \\\n",
    "--output_dir $output_directory_full \\\n",
    "--threshold 38\" >> $job_list_name\n",
    " fi\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUC_transformationETFBwk26.jobs\n",
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "echo $job_list_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During startup - Warning messages:\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\n",
      "1: Setting LC_COLLATE failed, using \"C\" \n",
      "2: Setting LC_TIME failed, using \"C\" \n",
      "3: Setting LC_MESSAGES failed, using \"C\" \n",
      "4: Setting LC_MONETARY failed, using \"C\" \n",
      "5: Setting LC_PAPER failed, using \"C\" \n",
      "6: Setting LC_MEASUREMENT failed, using \"C\" \n",
      "Running GMOdetector version 0.0.875\n",
      "load mode isload_full_then_crop\n",
      "Saving to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164345_0_0_0_Fluorescence_weights.hdf with key of weights\n",
      "Saving summary stats w/ threshold38.0 to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164345_0_0_0_Fluorescence_summary.csv\n",
      "Producing image channel for DsRed with cap 200 in color green\n",
      "Producing image channel for Chl with cap 200 in color red\n",
      "Producing image channel for Noise with cap 200 in color blue\n",
      "Saving image to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164345_0_0_0_Fluorescence.png\n",
      "Saving image metadata to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164345_0_0_0_Fluorescence.csv\n",
      "\n",
      "Finished running sample /mnt/Elements_24/EUC_transformation/ETFB/wk26//ETFB1_I5.0_F1.9_L100LED30_164345_0_0_0_Fluorescence.hdr in 17.740191336954013s\n",
      "\n",
      "During startup - Warning messages:\n",
      "1: Setting LC_COLLATE failed, using \"C\" \n",
      "2: Setting LC_TIME failed, using \"C\" \n",
      "3: Setting LC_MESSAGES failed, using \"C\" \n",
      "4: Setting LC_MONETARY failed, using \"C\" \n",
      "5: Setting LC_PAPER failed, using \"C\" \n",
      "6: Setting LC_MEASUREMENT failed, using \"C\" \n",
      "Running GMOdetector version 0.0.875\n",
      "load mode isload_full_then_crop\n",
      "Saving to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164427_1_0_2_Fluorescence_weights.hdf with key of weights\n",
      "Saving summary stats w/ threshold38.0 to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164427_1_0_2_Fluorescence_summary.csv\n",
      "Producing image channel for DsRed with cap 200 in color green\n",
      "Producing image channel for Chl with cap 200 in color red\n",
      "Producing image channel for Noise with cap 200 in color blue\n",
      "Saving image to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164427_1_0_2_Fluorescence.png\n",
      "Saving image metadata to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164427_1_0_2_Fluorescence.csv\n",
      "\n",
      "Finished running sample /mnt/Elements_24/EUC_transformation/ETFB/wk26//ETFB1_I5.0_F1.9_L100LED30_164427_1_0_2_Fluorescence.hdr in 18.34953331016004s\n",
      "\n",
      "During startup - Warning messages:\n",
      "1: Setting LC_COLLATE failed, using \"C\" \n",
      "2: Setting LC_TIME failed, using \"C\" \n",
      "3: Setting LC_MESSAGES failed, using \"C\" \n",
      "4: Setting LC_MONETARY failed, using \"C\" \n",
      "5: Setting LC_PAPER failed, using \"C\" \n",
      "6: Setting LC_MEASUREMENT failed, using \"C\" \n",
      "Running GMOdetector version 0.0.875\n",
      "load mode isload_full_then_crop\n",
      "Saving to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164526_2_0_5_Fluorescence_weights.hdf with key of weights\n",
      "Saving summary stats w/ threshold38.0 to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164526_2_0_5_Fluorescence_summary.csv\n",
      "Producing image channel for DsRed with cap 200 in color green\n",
      "Producing image channel for Chl with cap 200 in color red\n",
      "Producing image channel for Noise with cap 200 in color blue\n",
      "Saving image to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164526_2_0_5_Fluorescence.png\n",
      "Saving image metadata to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164526_2_0_5_Fluorescence.csv\n",
      "\n",
      "Finished running sample /mnt/Elements_24/EUC_transformation/ETFB/wk26//ETFB1_I5.0_F1.9_L100LED30_164526_2_0_5_Fluorescence.hdr in 18.095019601052627s\n",
      "\n",
      "During startup - Warning messages:\n",
      "1: Setting LC_COLLATE failed, using \"C\" \n",
      "2: Setting LC_TIME failed, using \"C\" \n",
      "3: Setting LC_MESSAGES failed, using \"C\" \n",
      "4: Setting LC_MONETARY failed, using \"C\" \n",
      "5: Setting LC_PAPER failed, using \"C\" \n",
      "6: Setting LC_MEASUREMENT failed, using \"C\" \n",
      "Running GMOdetector version 0.0.875\n",
      "load mode isload_full_then_crop\n",
      "Saving to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164634_3_0_6_Fluorescence_weights.hdf with key of weights\n",
      "Saving summary stats w/ threshold38.0 to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164634_3_0_6_Fluorescence_summary.csv\n",
      "Producing image channel for DsRed with cap 200 in color green\n",
      "Producing image channel for Chl with cap 200 in color red\n",
      "Producing image channel for Noise with cap 200 in color blue\n",
      "Saving image to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164634_3_0_6_Fluorescence.png\n",
      "Saving image metadata to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164634_3_0_6_Fluorescence.csv\n",
      "\n",
      "Finished running sample /mnt/Elements_24/EUC_transformation/ETFB/wk26//ETFB1_I5.0_F1.9_L100LED30_164634_3_0_6_Fluorescence.hdr in 18.421597586013377s\n",
      "\n",
      "During startup - Warning messages:\n",
      "1: Setting LC_COLLATE failed, using \"C\" \n",
      "2: Setting LC_TIME failed, using \"C\" \n",
      "3: Setting LC_MESSAGES failed, using \"C\" \n",
      "4: Setting LC_MONETARY failed, using \"C\" \n",
      "5: Setting LC_PAPER failed, using \"C\" \n",
      "6: Setting LC_MEASUREMENT failed, using \"C\" \n",
      "Running GMOdetector version 0.0.875\n",
      "load mode isload_full_then_crop\n",
      "Saving to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164730_4_1_5_Fluorescence_weights.hdf with key of weights\n",
      "Saving summary stats w/ threshold38.0 to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164730_4_1_5_Fluorescence_summary.csv\n",
      "Producing image channel for DsRed with cap 200 in color green\n",
      "Producing image channel for Chl with cap 200 in color red\n",
      "Producing image channel for Noise with cap 200 in color blue\n",
      "Saving image to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164730_4_1_5_Fluorescence.png\n",
      "Saving image metadata to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164730_4_1_5_Fluorescence.csv\n",
      "\n",
      "Finished running sample /mnt/Elements_24/EUC_transformation/ETFB/wk26//ETFB1_I5.0_F1.9_L100LED30_164730_4_1_5_Fluorescence.hdr in 18.309878109954298s\n",
      "\n",
      "During startup - Warning messages:\n",
      "1: Setting LC_COLLATE failed, using \"C\" \n",
      "2: Setting LC_TIME failed, using \"C\" \n",
      "3: Setting LC_MESSAGES failed, using \"C\" \n",
      "4: Setting LC_MONETARY failed, using \"C\" \n",
      "5: Setting LC_PAPER failed, using \"C\" \n",
      "6: Setting LC_MEASUREMENT failed, using \"C\" \n",
      "Running GMOdetector version 0.0.875\n",
      "load mode isload_full_then_crop\n",
      "Saving to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164820_5_1_4_Fluorescence_weights.hdf with key of weights\n",
      "Saving summary stats w/ threshold38.0 to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164820_5_1_4_Fluorescence_summary.csv\n",
      "Producing image channel for DsRed with cap 200 in color green\n",
      "Producing image channel for Chl with cap 200 in color red\n",
      "Producing image channel for Noise with cap 200 in color blue\n",
      "Saving image to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164820_5_1_4_Fluorescence.png\n",
      "Saving image metadata to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164820_5_1_4_Fluorescence.csv\n",
      "\n",
      "Finished running sample /mnt/Elements_24/EUC_transformation/ETFB/wk26//ETFB1_I5.0_F1.9_L100LED30_164820_5_1_4_Fluorescence.hdr in 18.832373060053214s\n",
      "\n",
      "During startup - Warning messages:\n",
      "1: Setting LC_COLLATE failed, using \"C\" \n",
      "2: Setting LC_TIME failed, using \"C\" \n",
      "3: Setting LC_MESSAGES failed, using \"C\" \n",
      "4: Setting LC_MONETARY failed, using \"C\" \n",
      "5: Setting LC_PAPER failed, using \"C\" \n",
      "6: Setting LC_MEASUREMENT failed, using \"C\" \n",
      "Running GMOdetector version 0.0.875\n",
      "load mode isload_full_then_crop\n",
      "Saving to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164916_6_1_3_Fluorescence_weights.hdf with key of weights\n",
      "Saving summary stats w/ threshold38.0 to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164916_6_1_3_Fluorescence_summary.csv\n",
      "Producing image channel for DsRed with cap 200 in color green\n",
      "Producing image channel for Chl with cap 200 in color red\n",
      "Producing image channel for Noise with cap 200 in color blue\n",
      "Saving image to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164916_6_1_3_Fluorescence.png\n",
      "Saving image metadata to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_164916_6_1_3_Fluorescence.csv\n",
      "\n",
      "Finished running sample /mnt/Elements_24/EUC_transformation/ETFB/wk26//ETFB1_I5.0_F1.9_L100LED30_164916_6_1_3_Fluorescence.hdr in 18.129377017030492s\n",
      "\n",
      "During startup - Warning messages:\n",
      "1: Setting LC_COLLATE failed, using \"C\" \n",
      "2: Setting LC_TIME failed, using \"C\" \n",
      "3: Setting LC_MESSAGES failed, using \"C\" \n",
      "4: Setting LC_MONETARY failed, using \"C\" \n",
      "5: Setting LC_PAPER failed, using \"C\" \n",
      "6: Setting LC_MEASUREMENT failed, using \"C\" \n",
      "Running GMOdetector version 0.0.875\n",
      "load mode isload_full_then_crop\n",
      "Saving to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165013_7_1_2_Fluorescence_weights.hdf with key of weights\n",
      "Saving summary stats w/ threshold38.0 to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165013_7_1_2_Fluorescence_summary.csv\n",
      "Producing image channel for DsRed with cap 200 in color green\n",
      "Producing image channel for Chl with cap 200 in color red\n",
      "Producing image channel for Noise with cap 200 in color blue\n",
      "Saving image to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165013_7_1_2_Fluorescence.png\n",
      "Saving image metadata to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165013_7_1_2_Fluorescence.csv\n",
      "\n",
      "Finished running sample /mnt/Elements_24/EUC_transformation/ETFB/wk26//ETFB1_I5.0_F1.9_L100LED30_165013_7_1_2_Fluorescence.hdr in 18.085146624129266s\n",
      "\n",
      "During startup - Warning messages:\n",
      "1: Setting LC_COLLATE failed, using \"C\" \n",
      "2: Setting LC_TIME failed, using \"C\" \n",
      "3: Setting LC_MESSAGES failed, using \"C\" \n",
      "4: Setting LC_MONETARY failed, using \"C\" \n",
      "5: Setting LC_PAPER failed, using \"C\" \n",
      "6: Setting LC_MEASUREMENT failed, using \"C\" \n",
      "Running GMOdetector version 0.0.875\n",
      "load mode isload_full_then_crop\n",
      "Saving to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165109_8_1_1_Fluorescence_weights.hdf with key of weights\n",
      "Saving summary stats w/ threshold38.0 to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165109_8_1_1_Fluorescence_summary.csv\n",
      "Producing image channel for DsRed with cap 200 in color green\n",
      "Producing image channel for Chl with cap 200 in color red\n",
      "Producing image channel for Noise with cap 200 in color blue\n",
      "Saving image to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165109_8_1_1_Fluorescence.png\n",
      "Saving image metadata to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165109_8_1_1_Fluorescence.csv\n",
      "\n",
      "Finished running sample /mnt/Elements_24/EUC_transformation/ETFB/wk26//ETFB1_I5.0_F1.9_L100LED30_165109_8_1_1_Fluorescence.hdr in 18.604549404932186s\n",
      "\n",
      "During startup - Warning messages:\n",
      "1: Setting LC_COLLATE failed, using \"C\" \n",
      "2: Setting LC_TIME failed, using \"C\" \n",
      "3: Setting LC_MESSAGES failed, using \"C\" \n",
      "4: Setting LC_MONETARY failed, using \"C\" \n",
      "5: Setting LC_PAPER failed, using \"C\" \n",
      "6: Setting LC_MEASUREMENT failed, using \"C\" \n",
      "Running GMOdetector version 0.0.875\n",
      "load mode isload_full_then_crop\n",
      "Saving to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165206_9_2_2_Fluorescence_weights.hdf with key of weights\n",
      "Saving summary stats w/ threshold38.0 to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165206_9_2_2_Fluorescence_summary.csv\n",
      "Producing image channel for DsRed with cap 200 in color green\n",
      "Producing image channel for Chl with cap 200 in color red\n",
      "Producing image channel for Noise with cap 200 in color blue\n",
      "Saving image to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165206_9_2_2_Fluorescence.png\n",
      "Saving image metadata to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165206_9_2_2_Fluorescence.csv\n",
      "\n",
      "Finished running sample /mnt/Elements_24/EUC_transformation/ETFB/wk26//ETFB1_I5.0_F1.9_L100LED30_165206_9_2_2_Fluorescence.hdr in 18.499071869067848s\n",
      "\n",
      "During startup - Warning messages:\n",
      "1: Setting LC_COLLATE failed, using \"C\" \n",
      "2: Setting LC_TIME failed, using \"C\" \n",
      "3: Setting LC_MESSAGES failed, using \"C\" \n",
      "4: Setting LC_MONETARY failed, using \"C\" \n",
      "5: Setting LC_PAPER failed, using \"C\" \n",
      "6: Setting LC_MEASUREMENT failed, using \"C\" \n",
      "Running GMOdetector version 0.0.875\n",
      "load mode isload_full_then_crop\n",
      "Saving to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165345_11_2_4_Fluorescence_weights.hdf with key of weights\n",
      "Saving summary stats w/ threshold38.0 to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165345_11_2_4_Fluorescence_summary.csv\n",
      "Producing image channel for DsRed with cap 200 in color green\n",
      "Producing image channel for Chl with cap 200 in color red\n",
      "Producing image channel for Noise with cap 200 in color blue\n",
      "Saving image to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165345_11_2_4_Fluorescence.png\n",
      "Saving image metadata to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165345_11_2_4_Fluorescence.csv\n",
      "\n",
      "Finished running sample /mnt/Elements_24/EUC_transformation/ETFB/wk26//ETFB1_I5.0_F1.9_L100LED30_165345_11_2_4_Fluorescence.hdr in 18.31708029517904s\n",
      "\n",
      "During startup - Warning messages:\n",
      "1: Setting LC_COLLATE failed, using \"C\" \n",
      "2: Setting LC_TIME failed, using \"C\" \n",
      "3: Setting LC_MESSAGES failed, using \"C\" \n",
      "4: Setting LC_MONETARY failed, using \"C\" \n",
      "5: Setting LC_PAPER failed, using \"C\" \n",
      "6: Setting LC_MEASUREMENT failed, using \"C\" \n",
      "Running GMOdetector version 0.0.875\n",
      "load mode isload_full_then_crop\n",
      "Saving to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165441_12_2_6_Fluorescence_weights.hdf with key of weights\n",
      "Saving summary stats w/ threshold38.0 to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165441_12_2_6_Fluorescence_summary.csv\n",
      "Producing image channel for DsRed with cap 200 in color green\n",
      "Producing image channel for Chl with cap 200 in color red\n",
      "Producing image channel for Noise with cap 200 in color blue\n",
      "Saving image to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165441_12_2_6_Fluorescence.png\n",
      "Saving image metadata to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165441_12_2_6_Fluorescence.csv\n",
      "\n",
      "Finished running sample /mnt/Elements_24/EUC_transformation/ETFB/wk26//ETFB1_I5.0_F1.9_L100LED30_165441_12_2_6_Fluorescence.hdr in 17.55155033688061s\n",
      "\n",
      "During startup - Warning messages:\n",
      "1: Setting LC_COLLATE failed, using \"C\" \n",
      "2: Setting LC_TIME failed, using \"C\" \n",
      "3: Setting LC_MESSAGES failed, using \"C\" \n",
      "4: Setting LC_MONETARY failed, using \"C\" \n",
      "5: Setting LC_PAPER failed, using \"C\" \n",
      "6: Setting LC_MEASUREMENT failed, using \"C\" \n",
      "Running GMOdetector version 0.0.875\n",
      "load mode isload_full_then_crop\n",
      "Saving to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165924_0_2_3_Fluorescence_weights.hdf with key of weights\n",
      "Saving summary stats w/ threshold38.0 to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165924_0_2_3_Fluorescence_summary.csv\n",
      "Producing image channel for DsRed with cap 200 in color green\n",
      "Producing image channel for Chl with cap 200 in color red\n",
      "Producing image channel for Noise with cap 200 in color blue\n",
      "Saving image to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165924_0_2_3_Fluorescence.png\n",
      "Saving image metadata to /mnt/output/gmodetector_out/EUC_transformation/ETFB/wk26/ETFB1_I5.0_F1.9_L100LED30_165924_0_2_3_Fluorescence.csv\n",
      "\n",
      "Finished running sample /mnt/Elements_24/EUC_transformation/ETFB/wk26//ETFB1_I5.0_F1.9_L100LED30_165924_0_2_3_Fluorescence.hdr in 18.283190800109878s\n",
      "\n",
      "\u001b[?2004h(cubeglm) \u001b[?2004l\u001b[?2004l\u001b[?2004l"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "conda activate cubeglm\n",
    "\n",
    "if [ $parallel -eq 1 ]\n",
    "then\n",
    "    parallel --jobs 20 -a $job_list_name\n",
    "fi\n",
    "\n",
    "if [ $parallel -eq 0 ]\n",
    "then\n",
    "    bash $job_list_name\n",
    "fi\n",
    "\n",
    "conda deactivate\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time regression completes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 25 12:27:57 PST 2023\n",
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "echo $(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic segmentation of tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are segmented into specific plant tissues by a deep neural network of the state-of-the-art Deeplab v3 architecture <a href=\"https://arxiv.org/abs/1706.05587\" target=\"_blank\">Liang-Chieh et al., 2017</a>. The model has been trained using training sets generated with our annotation GUI Intelligent DEep Annotator for Segmentation (IDEAS, available on <a href=\"https://bitbucket.org/JialinYuan/image-annotator/src/master/\" target=\"_blank\">Bitbucket</a>, publication pending). Our branch of the Deeplab v3 repo, including a Jupyter walkthrough for training, can be found on Github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is completed upstream of this notebook, which only entails analysis of test data using the latest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/downsized/segmentation_composite2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: This example image was taken from an experiment on the effects of different CIMs on cottonwood regeneration. This composite image illustrates that for every sample, tissues are segmented into stem (red), callus (blue) and shoot (green). These composite images, useful for manual inspection of results, are produced when the 'composite' option is on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We desire for images to all be in the same orientation. At one point, the camera on the *macroPhor Array* was set to automatically detect orientation, which led to images randomly being in portrait or landscape. Here we will standardize the orientation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perl: warning: Setting locale failed.[?2004l\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLANGUAGE = (unset),\n",
      "\tLC_ALL = (unset),\n",
      "\tLC_CTYPE = \"C.UTF-8\",\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the standard locale (\"C\").\n",
      "perl: warning: Setting locale failed.\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLANGUAGE = (unset),\n",
      "\tLC_ALL = (unset),\n",
      "\tLC_CTYPE = \"C.UTF-8\",\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the standard locale (\"C\").\n",
      "perl: warning: Setting locale failed.\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLANGUAGE = (unset),\n",
      "\tLC_ALL = (unset),\n",
      "\tLC_CTYPE = \"C.UTF-8\",\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the standard locale (\"C\").\n",
      "perl: warning: Setting locale failed.\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLANGUAGE = (unset),\n",
      "\tLC_ALL = (unset),\n",
      "\tLC_CTYPE = \"C.UTF-8\",\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the standard locale (\"C\").\n",
      "perl: warning: Setting locale failed.\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLANGUAGE = (unset),\n",
      "\tLC_ALL = (unset),\n",
      "\tLC_CTYPE = \"C.UTF-8\",\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the standard locale (\"C\").\n",
      "perl: warning: Setting locale failed.\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLANGUAGE = (unset),\n",
      "\tLC_ALL = (unset),\n",
      "\tLC_CTYPE = \"C.UTF-8\",\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the standard locale (\"C\").\n",
      "perl: warning: Setting locale failed.\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLANGUAGE = (unset),\n",
      "\tLC_ALL = (unset),\n",
      "\tLC_CTYPE = \"C.UTF-8\",\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the standard locale (\"C\").\n",
      "perl: warning: Setting locale failed.\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLANGUAGE = (unset),\n",
      "\tLC_ALL = (unset),\n",
      "\tLC_CTYPE = \"C.UTF-8\",\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the standard locale (\"C\").\n",
      "perl: warning: Setting locale failed.\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLANGUAGE = (unset),\n",
      "\tLC_ALL = (unset),\n",
      "\tLC_CTYPE = \"C.UTF-8\",\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the standard locale (\"C\").\n",
      "perl: warning: Setting locale failed.\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLANGUAGE = (unset),\n",
      "\tLC_ALL = (unset),\n",
      "\tLC_CTYPE = \"C.UTF-8\",\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the standard locale (\"C\").\n",
      "perl: warning: Setting locale failed.\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLANGUAGE = (unset),\n",
      "\tLC_ALL = (unset),\n",
      "\tLC_CTYPE = \"C.UTF-8\",\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the standard locale (\"C\").\n",
      "perl: warning: Setting locale failed.\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLANGUAGE = (unset),\n",
      "\tLC_ALL = (unset),\n",
      "\tLC_CTYPE = \"C.UTF-8\",\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the standard locale (\"C\").\n",
      "perl: warning: Setting locale failed.\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLANGUAGE = (unset),\n",
      "\tLC_ALL = (unset),\n",
      "\tLC_CTYPE = \"C.UTF-8\",\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the standard locale (\"C\").\n",
      "perl: warning: Setting locale failed.\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLANGUAGE = (unset),\n",
      "\tLC_ALL = (unset),\n",
      "\tLC_CTYPE = \"C.UTF-8\",\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the standard locale (\"C\").\n",
      "\u001b[?2004h(alignment) \u001b[?2004l\u001b[?2004l"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "conda activate alignment\n",
    "for filename in $data/*.jpg; do\n",
    "    exiftool -Orientation=8 -n $filename > ${data}log_exiftool.txt\n",
    "    done\n",
    "conda deactivate\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "rm -f $data/*original*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crop and resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script resizes images to 900x900 and then crops away top and bottom 150 pixels for a final image size of 900x600."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose for cropping is to remove labels, which has been standard practice for all training and testing. Otherwise, we could run into problems such as the neural network \"learning\" plants labeled as control have more or less regeneration.<br>The purpose for resizing is to reduce computational expense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# cd ${cwd}/intermediates/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h\u001b[?2004l\u001b[?2004l"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# conda activate base\n",
    "# python crop.py $data\n",
    "# conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare input list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script `inference.py` requires a list of all files to be analyzed. We will create this file as `test.csv`. This will be a list of all our (pre-processed) image files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h\u001b[?2004l"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# cd $data\n",
    "# ls -d $PWD/* $data | grep -i \"rgb_cropped.jpg\" > test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the chroma standard from list of RGB image data to be segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# sed -i '/hroma/d' \"${data}/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model is deployed to perform semantic segmentation of experimental images. A list of RGB images to be segmented by the trained model is passed through the --image-list option. For each of these images, we will obtain an output mask (.png) of labeled tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies include `opencv`, `scipy`, `yaml` and `tensorflow` (version 1.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/output\n",
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h\u001b[?2004l"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#conda activate cubeglm\n",
    "#conda install scikit-learn=1.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/Elements_24/EUC_transformation/ETFB/wk26/\n",
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "echo $data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_false_color_batch.py\n",
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "ls ${cubeml_path}/scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'scripts/batch_inference.py': [Errno 2] No such file or directory\n",
      "\u001b[?2004h(cubeglm2) \u001b[?2004l\u001b[?2004l"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cd $cubeml_path\n",
    "conda activate cubeglm2\n",
    "python scripts/batch_inference.py \\\n",
    "--dir $data \\\n",
    "--pickle $segmentation_model_path \\\n",
    "--method TNN \\\n",
    "--false_color \\\n",
    ">> $data/log_inference.txt\n",
    "conda deactivate\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up and reorganize files. Let's keep the outputs we need with all other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mv \"${deeplab_path}/segmentation_results/raw/\"* $data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name outputs to reflect that they are segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd $data\n",
    "#for file in *_rgb_cropped.png; do mv -f \"$file\" \"${file%_rgb_cropped.png}_segment_cropped.png\"; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-expand segment outputs to same size as original RGB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda activate alignment\n",
    "#cd $alignment_path\n",
    "#python expand.py $data >> $data/log_expand.txt\n",
    "#conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make composite images with side-by-side RGB, segmentation outputs and blended images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "composite=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_sum_stats_over_combined_segments.R\n",
      "email_to_send_template.txt\n",
      "email_to_send.txt\n",
      "\u001b[0m\u001b[01;34mexplant_position_key\u001b[0m\n",
      "grid_item_plots_a10.R\n",
      "grid_item_plots_a13.R\n",
      "grid_item_plots_debug_GTFF.R\n",
      "grid_item_plots_no_perm_stashed.R\n",
      "grid_item_plots.R\n",
      "grid_item_plots_troubleshoot_GTCC_wk7.R\n",
      "\u001b[01;34mgrids\u001b[0m\n",
      "\u001b[01;34mheritability\u001b[0m\n",
      "image_blender.py\n",
      "__init__.py\n",
      "main.py\n",
      "\u001b[01;34mplots\u001b[0m\n",
      "README.md\n",
      "setup.py\n",
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "ls $gmolabeler_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making composites[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\n",
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "if [ $composite -eq 1 ]\n",
    "then\n",
    "    echo \"making composites\"\n",
    "    conda activate test-environment\n",
    "    cd $gmolabeler_path\n",
    "    python image_blender.py $data 0.75 'both' 1 0 >> $data/log_blend.txt 2>&1\n",
    "    conda deactivate\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image_blender.py', '/media/gmobot/Elements_24/Elements_24/EUC_transformation/ETFB/wk26/', '0.75', 'both', '1', '180#']\n",
      "Number of segmentation files: 14\n",
      "Number of RGB files: 13\n",
      "Error: There is not a segmentation output for every rgb image.\n",
      "13\n",
      "14\n",
      "['image_blender.py', '/media/gmobot/Elements_24/Elements_24/EUC_transformation/ETFB/wk26/', '0.75', 'both', '1', '180#']\n",
      "Number of segmentation files: 14\n",
      "Number of RGB files: 13\n",
      "Error: There is not a segmentation output for every rgb image.\n",
      "13\n",
      "14\n",
      "['image_blender.py', '/media/gmobot/Elements_24/Elements_24/EUC_transformation/ETFB/wk26/', '0.75', 'both', '1', '180']\n",
      "Number of segmentation files: 14\n",
      "Number of RGB files: 13\n",
      "Error: There is not a segmentation output for every rgb image.\n",
      "13\n",
      "14\n",
      "['image_blender.py', '/media/gmobot/Elements_24/Elements_24/EUC_transformation/ETFB/wk26/', '0.75', 'both', '1', '180']\n",
      "Number of segmentation files: 13\n",
      "Number of RGB files: 13\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_164427_1_0_2_rgb.jpg\n",
      "Traceback (most recent call last):\n",
      "  File \"image_blender.py\", line 53, in <module>\n",
      "    main(wd = sys.argv[1],\n",
      "  File \"image_blender.py\", line 39, in main\n",
      "    image_blended = Image.blend(segment_img, rgb_img, alpha=float(alpha))\n",
      "  File \"/home/gmobot/anaconda3/envs/test-environment/lib/python3.8/site-packages/PIL/Image.py\", line 3167, in blend\n",
      "    return im1._new(core.blend(im1.im, im2.im, alpha))\n",
      "ValueError: images do not match\n",
      "['image_blender.py', '/media/gmobot/Elements_24/Elements_24/EUC_transformation/ETFB/wk26/', '0.75', 'both', '1', '180']\n",
      "Number of segmentation files: 13\n",
      "Number of RGB files: 13\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_164427_1_0_2_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_170554_1_0_2_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_164427_1_0_2_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_164526_2_0_5_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_170636_2_0_5_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_164526_2_0_5_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_164634_3_0_6_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_170727_3_0_6_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_164634_3_0_6_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_164730_4_1_5_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_170800_4_1_5_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_164730_4_1_5_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_164820_5_1_4_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_170834_5_1_4_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_164820_5_1_4_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_164916_6_1_3_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_170907_6_1_3_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_164916_6_1_3_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_165013_7_1_2_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_170940_7_1_2_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_165013_7_1_2_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_165109_8_1_1_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_171014_8_1_1_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_165109_8_1_1_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_165206_9_2_2_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_171047_9_2_2_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_165206_9_2_2_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_165345_11_2_4_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_171120_10_2_3_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_165345_11_2_4_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_165441_12_2_6_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_171153_11_2_4_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_165441_12_2_6_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_165924_0_2_3_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_171226_12_2_6_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_165924_0_2_3_rgb.jpg\n",
      "['image_blender.py', '/media/gmobot/Elements_24/Elements_24/EUC_transformation/ETFB/wk26/', '0.75', 'both', '1', '0']\n",
      "Number of segmentation files: 13\n",
      "Number of RGB files: 13\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_164427_1_0_2_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_170554_1_0_2_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_164427_1_0_2_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_164526_2_0_5_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_170636_2_0_5_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_164526_2_0_5_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_164634_3_0_6_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_170727_3_0_6_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_164634_3_0_6_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_164730_4_1_5_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_170800_4_1_5_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_164730_4_1_5_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_164820_5_1_4_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_170834_5_1_4_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_164820_5_1_4_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_164916_6_1_3_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_170907_6_1_3_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_164916_6_1_3_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_165013_7_1_2_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_170940_7_1_2_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_165013_7_1_2_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_165109_8_1_1_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_171014_8_1_1_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_165109_8_1_1_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_165206_9_2_2_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_171047_9_2_2_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_165206_9_2_2_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_165345_11_2_4_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_171120_10_2_3_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_165345_11_2_4_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_165441_12_2_6_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_171153_11_2_4_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_165441_12_2_6_rgb.jpg\n",
      "Building composite for image ETFB1_I5.0_F1.9_L100LED30_165924_0_2_3_rgb.jpg\n",
      "Warning: Dimensions do not match for ETFB1_I5.0_F1.9_L100LED30_171226_12_2_6_segment_uncropped.png and ETFB1_I5.0_F1.9_L100LED30_165924_0_2_3_rgb.jpg\n",
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cat $data/log_blend.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of contaminated/missing explants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plates are cropped into sub-images for each explant and each is analyzed to determine if the explant position should be excluded from analysis due to being missing or contamination. Missing and contaminated explants are recognized using a trained Densenet model (<a href=\"https://github.com/Contamination-Classification/DenseNet\" target=\"_blank\">Huang, et al. 2018</a>). Our fork of the Densenet repository is available on <a href=\"https://arxiv.org/abs/1608.06993\" target=\"_blank\">GitHub</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/Densenet.png\">\n",
    "Figure: These are four examples of contaminated explants used in the training set for this pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the grid cropping dimensions, we can run the following script. Note that these are the dimensions to crop the image to after resizing to 2000x2000 (from 4000x4000 in the case of the *macroPhor Array*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine grid cropping parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "pre_aligned_resized_grid_borders=\"Automatic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB data loaded, elapsed time: 0.20 seconds2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\n",
      "Calculations done, elapsed time: 0.21 seconds\n",
      "Coordinates saved, elapsed time: 0.22 seconds\n",
      "Plotting done, elapsed time: 46.55 seconds\n",
      "mode,x1,x2,y1,y2\n",
      "RGB,956,3197,502,3463\n",
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "if [ $pre_aligned_resized_grid_borders = \"Automatic\" ]; then\n",
    "    conda activate cubeglm2\n",
    "    cd \"${cwd}/intermediates/\"\n",
    "    python find_grid_position.py --mode RGB --cap 255 --index 0 --data $data --plot\n",
    "    \n",
    "    # Navigate to the data directory where coordinates.csv is saved\n",
    "    cd \"$data\"\n",
    "    \n",
    "    cat coordinates.csv\n",
    "\n",
    "    # Read the CSV file and extract x1, x2, y1, y2\n",
    "    firstline=1\n",
    "    while IFS=',' read -r mode x1 x2 y1 y2; do\n",
    "        if [ \"$firstline\" -eq \"0\" ]; then\n",
    "            # echo \"Debug x1: $x1\"\n",
    "            # echo \"Debug x2: $x2\"\n",
    "            # echo \"Debug y1: $y1\"\n",
    "            # echo \"Debug y2: $y2\"\n",
    "\n",
    "            # Divide by 2 and round to integer\n",
    "            x1=$(printf \"%.0f\" $(echo \"$x1 / 2\" | bc -l))\n",
    "            x2=$(printf \"%.0f\" $(echo \"$x2 / 2\" | bc -l))\n",
    "            y1=$(printf \"%.0f\" $(echo \"$y1 / 2\" | bc -l))\n",
    "            y2=$(printf \"%.0f\" $(echo \"$y2 / 2\" | bc -l))\n",
    "\n",
    "            pre_aligned_resized_grid_borders=\"$x1,$y1,$x2,$y2\"\n",
    "        fi\n",
    "        firstline=0\n",
    "    done < coordinates.csv\n",
    "    conda deactivate\n",
    "\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare list of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if [ $missing_explants = \"Automatic\" ]; then\n",
    "#    echo \"Missing explants will be inferred.\"\n",
    "#    cd $data\n",
    "#    ls -d $PWD/* $data | grep -i \"rgb.jpg\" > rgb_list.txt\n",
    "#    sed -i '/hroma/d' rgb_list.txt\n",
    "#    img_list_path=\"${data}/rgb_list.txt\"\n",
    "#else\n",
    "#    echo \"Missing explants input manually by user, in file: \"\n",
    "#    echo $missing_explants\n",
    "#fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the mode for missing explant data is automatic, prepare input file for script to detect missing explants and run this script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer contaminated/missing explants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# if [ $missing_explants = \"Automatic\" ]; then\n",
    "#     cd $contamination_path\n",
    "#     conda activate DenseNet\n",
    "#     python -W ignore inference.py \\\n",
    "#     --img-list=$img_list_path \\\n",
    "#     --crop_dims $pre_aligned_resized_grid_borders \\\n",
    "#     --output_file=output.csv >> $data/log_contam.txt\n",
    "#     mv -f output.csv \"${data}/output.csv\"\n",
    "#     conda deactivate\n",
    "# fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if [ $missing_explants = \"Automatic\" ]; then\n",
    "#     missing_explants=\"${data}/output.csv\"\n",
    "#     echo \"Missing explants inferred by model and written to file:\"\n",
    "#     echo $missing_explants\n",
    "# else\n",
    "#     echo \"Missing explants input manually by user, in file: \"\n",
    "#     echo $missing_explants\n",
    "# fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment of RGB and hyperspectral layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match the frame and angle of RGB and hyperspectral image layers, we perform a homography transformation using a method described [in these notebooks](https://github.com/naglemi/GMOnotebook/tree/master/1_Decide_parameters/2_Align_and_crop_parameters/2_find_alignment_parameters). Using a pair of standard images, a homography matrix is calculated for the necessary transformation of RGB images to align with hyperspectral images. The transformation can then be applied to large batches of images rapidly, as long as the RGB and hyperspectral cameras remain in the same positions relative to one another (as they do in the macroPhor Array platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/Alignment.png\">\n",
    "Figure: To enable precise calculation of a homography matrix for transformation of RGB images to match hyperspectral images, we used images of a piece of paper with grid marks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `opencv` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare file lists for alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> We will produce two lists: one for hyperspectral channels (chlorophyll peak channel) for each sample and another for the complementary RGB images. We will superimpose them and produce images for inspection, allowing the user to make sure the alignment works reliably for all images. However, it is possible to replace the hyperspectral channels for each image with a single file; this would run more quickly but be less useful for allowing the user to validate alignment results.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to produce a csv with two columns with headers `hyper_img` and `rgb_images`. For each RGB image being transformed in batch alignment (mode 2), we can test the alignment by producing superimposed images of the transformed RGB images together with a hyperspectral layer. The hyperspectral layer can either be for a grid (fast) or can be for a layer extracted from the hyperspectral image of each channel (slow, but useful for making sure a certain homography matrix works reliably to transform a batch of images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ $mode = \"opencv\" ]; then # Generate list for column column `rgb_images`, then another for hyperspectral, and merge\n",
    "    cd $data\n",
    "    ls | grep -i 'rgb\\.jpg' > file_list_part1.csv\n",
    "    ls | grep -i 'segment_uncropped\\.png' > file_list_part2.csv\n",
    "    cat file_list_part* > file_list.csv\n",
    "    # sed -i '/hroma/d' file_list.csv\n",
    "    cwd2=$(pwd)/\n",
    "    awk -v prefix=\"$cwd2\" '{print prefix $0}' file_list.csv > temp\n",
    "    mv -f temp file_list.csv\n",
    "    echo 'rgb_images' | cat - file_list.csv > temp && mv -f temp file_list.csv\n",
    "    cp file_list.csv file_list_hyper_channel.csv\n",
    "    sed -i 's/_rgb.jpg/_hyperchannel.csv/g' file_list_hyper_channel.csv\n",
    "    sed -i 's/rgb_images/hyper_img/g' file_list_hyper_channel.csv\n",
    "    sed -i 's/_segment_uncropped.png/_hyperchannel.csv/g' file_list_hyper_channel.csv\n",
    "    paste --delimiters=',' file_list_hyper_channel.csv file_list.csv > rgb_and_hyper_channel_lists.csv\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run batch alignment to apply homography matrix to all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ $mode = \"opencv\" ]; then\n",
    "    conda activate alignment\n",
    "    cd $alignment_path\n",
    "    file_list_input=\"${data}/rgb_and_hyper_channel_lists.csv\"\n",
    "    python main.py \\\n",
    "    --hyper-img $hypercube_csv \\\n",
    "    --img-csv $file_list_input \\\n",
    "    --mode 2 \\\n",
    "    --h_matrix_path $homography >> $data/log_alignment_mode2.txt\n",
    "    conda deactivate\n",
    "    conda deactivate\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `scikit` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this similar, but simpler approach, a homography matrix is manually generated by the user as shown in the `manual_alignment` notebooks in the GMOnotebook repository. This is notably different from how these matrices are automatically generated with the `opencv` method (which is not always perfectly robust). This homography matrix is then used to batch-transform all images for this dataset, similarly to the `opencv` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypercube_jpg=$(echo $hypercube_csv | sed -e 's/\\.csv/.jpg/g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ $mode = \"scikit\" ]; then\n",
    "    conda activate alignment\n",
    "    python $cwd/manual_alignment/batch_align_manual.py \\\n",
    "    --img_dir $data \\\n",
    "    --hyp_path $hypercube_jpg \\\n",
    "    --matrix $homography\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-analyze deep segmentation and regression results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripts in the <a href=\"https://github.com/naglemi/GMOlabeler\" target=\"_blank\">GMOlabeler repository</a> are used to cross-reference results from deep segmentation of RGB images and regression of hyperspectral imaging, apply thresholding parameters to classify tissues as transgenic or escapes, and produce plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/GMOlabeler.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: The various steps of data processing in GMOlabeler are illustrated for an example explant from an experiment on CIM optimization for cottonwood. Images of plates are cropped to a sub-image for each explant. RGB segmentation results and hyperspectral regression results are cross-referenced to calculate fluorecent proteins in specific tissues and infer whether these tissues are transgenic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare sample datasheet input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input file we will use for making plots. This file contains paths to CLS results, RGB images, and hyperspectral images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"”2023-11-01”\"r) \u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\n",
      "[1] \"Looking for CLS data in: /media/gmobot/data/gmodetector_out/Elements_24/EUC_transformation/ETFB/wk26//\"\n",
      "[1] \"2023-11-01\"\n",
      "[1] \"Looking for CLS files in directory /media/gmobot/data/gmodetector_out/Elements_24/EUC_transformation/ETFB/wk26//\"\n",
      "[1] \"How many CLS files? 13\"\n",
      "[1] \"Writing 13 rows to /media/gmobot/Elements_24/Elements_24/EUC_transformation/ETFB/wk26///samples_pre_labeling.csv\"\n",
      "\u001b[?2004h(gmolabeler) \u001b[?2004l\u001b[?2004l"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "conda activate gmolabeler\n",
    "cd \"${cwd}/intermediates/\"\n",
    "\n",
    "# Check if segmentation_mode is set to \"hyperspectral\"\n",
    "if [ \"$segmentation_mode\" = \"hyperspectral\" ]; then\n",
    "  Rscript pre_label.R \\\n",
    "  -r \"${data}/\" \\\n",
    "  -R \"${output_directory_prefix}\" \\\n",
    "  -i 1 \\\n",
    "  -d $datestamp \\\n",
    "  --segmentation_model_key $segmentation_model_key # Only included if segmentation_mode is hyperspectral\n",
    "else\n",
    "  Rscript pre_label.R \\\n",
    "  -r \"${data}/\" \\\n",
    "  -R \"${output_directory_prefix}\" \\\n",
    "  -i 1 \\\n",
    "  -d $datestamp\n",
    "fi\n",
    "\n",
    "conda deactivate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-reference RGB and hyperspectral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h(cubeglm2) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "aligned_grid_borders=\"Automatic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of aligned_grid_borders:\n",
      "Automaticcubeglm2) \u001b[?2004l\n",
      "Selected file: ['chromagrid_I5.0_F1.9_L100LED30_181416_0_1_4_Broadband.hdr'][?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\n",
      "/home/gmobot/anaconda3/envs/cubeglm2/lib/python3.8/site-packages/spectral/io/envi.py:175: UserWarning: Parameters with non-lowercase names encountered and converted to lowercase. To retain source file parameter name capitalization, set spectral.settings.envi_support_nonlowercase_params to True.\n",
      "  warnings.warn(msg)\n",
      "Extracting channel at index 130\n",
      "Hyperspectral data loaded, elapsed time: 0.03 seconds\n",
      "Calculations done, elapsed time: 0.03 seconds\n",
      "Coordinates saved, elapsed time: 0.03 seconds\n",
      "Plotting done, elapsed time: 22.86 seconds\n",
      "mode,x1,x2,y1,y2\n",
      "hyperspectral,121,1290,275,1217\n",
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "echo \"Value of aligned_grid_borders:\"\n",
    "echo $aligned_grid_borders\n",
    "if [ \"$aligned_grid_borders\" = \"Automatic\" ]; then\n",
    "    conda activate cubeglm2\n",
    "    cd \"${cwd}/intermediates/\"\n",
    "    python find_grid_position.py --mode hyperspectral --cap 500 --index 130 --data $data \\\n",
    "    --rotation 270 --flip_horizontal --plot\n",
    "    \n",
    "    # Navigate to the data directory where coordinates.csv is saved\n",
    "    cd \"$data\"\n",
    "    \n",
    "    cat coordinates.csv\n",
    "\n",
    "    # Read the CSV file and extract x1, x2, y1, y2\n",
    "    firstline=1\n",
    "    while IFS=',' read -r mode x1 x2 y1 y2; do\n",
    "        if [ \"$firstline\" -eq \"0\" ]; then\n",
    "            # echo \"Debug x1: $x1\"\n",
    "            # echo \"Debug x2: $x2\"\n",
    "            # echo \"Debug y1: $y1\"\n",
    "            # echo \"Debug y2: $y2\"\n",
    "\n",
    "            aligned_grid_borders=\"$x1 $x2 $y2 $y1\"\n",
    "        fi\n",
    "        firstline=0\n",
    "    done < coordinates.csv\n",
    "    conda deactivate\n",
    "\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "aligned_grid=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No grid found at a path given by user, searching for one...2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\n",
      "Grid found: /media/gmobot/Elements_24/Elements_24/EUC_transformation/ETFB/wk26/chromagrid_I5.0_F1.9_L100LED30_181416_0_1_4_rgb_processed.png.png\n",
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# Check if $aligned_grid is unset or the file doesn't exist\n",
    "if [[ -z \"$aligned_grid\" || ! -f \"$aligned_grid\" ]]; then\n",
    "  echo \"No grid found at a path given by user, searching for one...\"\n",
    "\n",
    "    # Find the most recent file matching the criteria in the current directory only\n",
    "    aligned_grid=$(find \"$data\" -maxdepth 1 -type f -name \"*hroma*rgb_processed.png*\" ! -name \"*csv*\" -printf '%T+ %p\\n' | sort -r | head -n 1 | cut -d\" \" -f2-)\n",
    "\n",
    "  # Check if a file was found\n",
    "  if [[ -z \"$aligned_grid\" ]]; then\n",
    "    echo \"No suitable grid file found.\"\n",
    "  else\n",
    "    # Output the found path\n",
    "    echo \"Grid found: $aligned_grid\"\n",
    "  fi\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h(gmolabeler) \u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "conda activate gmolabeler\n",
    "cd $gmolabeler_path\n",
    "\n",
    "for reporter in ${reporters[@]}; do\n",
    "    # Start the command with the basic arguments\n",
    "    cmd=\"python main.py \\\n",
    "    \\\"${data}/samples_pre_labeling.csv\\\" \\\n",
    "    $aligned_grid \\\n",
    "    $reporter_threshold \\\n",
    "    $reporter \\\n",
    "    $grid \\\n",
    "    \\\"hdf\\\" \\\n",
    "    $gmolabeler_path\"\n",
    "\n",
    "    # Append the grid borders to the command\n",
    "    if [[ -n \"$aligned_grid_borders\" ]]; then\n",
    "        cmd+=\" \\\"$aligned_grid_borders\\\"\"\n",
    "    fi\n",
    "\n",
    "    # Check if segmentation_model_key is set and points to a file\n",
    "    if [[ -n $segmentation_model_key && -f $segmentation_model_key ]]; then\n",
    "        # Append the segmentation model key to the command as a named argument\n",
    "        cmd+=\" --segmentation_model_key \\\"$segmentation_model_key\\\"\"\n",
    "    fi\n",
    "\n",
    "    # Run the command and redirect stdout to the log file\n",
    "    eval $cmd > \"$data/log_gmolabeler_$reporter.txt\"\n",
    "\n",
    "done\n",
    "\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 2 max value after scaling: 51\n",
      "debugging CLS_to_image\n",
      "debugging CLS_to_image\n",
      "Warning: RGB color is (0, 0, 0), which will result in a black image.\n",
      "Warning: The image data is all zeros before creating the PIL Image.\n",
      "debugging CLS_to_image\n",
      "debugging CLS_to_image\n",
      "debugging CLS_to_image\n",
      "debugging CLS_to_image\n",
      "Warning: The image for Background is entirely black.\n",
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "tail \"$data/log_gmolabeler_$reporter.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate sums of statistics over combined segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in all regenerated tissue (callus + shoot) as well as all tissue (including stem as well). We will calculate aggregate statistics over these groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",Tissue,hex_code,Integer\n",
      "0,Background,#000000,0\n",
      "1,Callus,#0000FF,1\n",
      "2,Necrotic,#964B00,2\n",
      "3,Explant,#FF0000,3\n",
      "4,Shoot,#AADB1E,4\n",
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cat $segmentation_model_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background Explant Necrotic\n",
      "\u001b[?2004h"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "echo $unregenerated_tissues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h(gmolabeler) \u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\n",
      "[1] \"Completed for whole-tissue batch\"\n",
      "[1] \"Now to compute only for regenerated tissues\"\n",
      "[1] \"Rows before excluding: \"\n",
      "[1] 781\n",
      "[1] \"Rows after excluding: \"\n",
      "[1] 313\n",
      "[1] \"Writing to /home/gmobot/GMOlabeler//output/Elements_24/EUC_transformation/ETFB/wk26//DsRed/stats_with_sums_over_tissues.csv\"\n",
      "[1] \"Script completed successfully.\"\n",
      "\n",
      "[1] \"Completed for whole-tissue batch\"\n",
      "[1] \"Now to compute only for regenerated tissues\"\n",
      "[1] \"Rows before excluding: \"\n",
      "[1] 781\n",
      "[1] \"Rows after excluding: \"\n",
      "[1] 313\n",
      "[1] \"Writing to /home/gmobot/GMOlabeler//output/Elements_24/EUC_transformation/ETFB/wk26//Chl/stats_with_sums_over_tissues.csv\"\n",
      "[1] \"Script completed successfully.\"\n",
      "\u001b[?2004h(gmolabeler) \u001b[?2004l"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "conda activate gmolabeler\n",
    "cd $gmolabeler_path\n",
    "\n",
    "for reporter in \"${reporters[@]}\"; do\n",
    "    # Start the command with the base part\n",
    "    cmd=\"Rscript calculate_sum_stats_over_combined_segments.R \\\n",
    "    --output_dir \\\"${gmolabeler_path}/output/\\\" \\\n",
    "    --datapath \\\"${data_folder}/${reporter}/\\\"\"\n",
    "\n",
    "    # Append the model key path if it's set and not None\n",
    "    if [ -n \"${segmentation_model_key}\" ] && [ \"${segmentation_model_key}\" != \"None\" ]; then\n",
    "        cmd+=\" --keypath \\\"${segmentation_model_key}\\\"\"\n",
    "    fi\n",
    "\n",
    "    # Append the exclude tissues string if it's set and not None\n",
    "    if [ -n \"${unregenerated_tissues}\" ] && [ \"${unregenerated_tissues}\" != \"None\" ]; then\n",
    "        echo $exclude_tissues\n",
    "        cmd+=\" --exclude_tissues \\\"${unregenerated_tissues}\\\"\"\n",
    "    fi\n",
    "\n",
    "    # Execute the command\n",
    "    eval $cmd\n",
    "done\n",
    "conda deactivate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make plots of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25hError in library(buildmer) : there is no package called ‘buildmer’04l\u001b[?2004l\u001b[?2004l\u001b[?2004l\u001b[?2004l\n",
      "Execution halted\n",
      "\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25hError in library(buildmer) : there is no package called ‘buildmer’\n",
      "Execution halted\n",
      "\u001b[?2004h?2004h(gmolabeler) \u001b[?2004l"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "conda activate gmolabeler\n",
    "cd $gmolabeler_path\n",
    "for reporter in ${reporters[@]}; do\n",
    "    Rscript grid_item_plots.R \\\n",
    "    -d \"${data_folder}/\" \\\n",
    "    -r \"$randomization_datasheet\" \\\n",
    "    -p $pixel_threshold \\\n",
    "    -v categorical \\\n",
    "    -m 1 \\\n",
    "    -M $missing_explants \\\n",
    "    -g $grid \\\n",
    "    --samples-pre-labeling ${data}/samples_pre_labeling.csv \\\n",
    "    --sort 1 \\\n",
    "    --height $height \\\n",
    "    --width $width \\\n",
    "    --Reporter $reporter\n",
    "done\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean-up some outputs, re-organize some files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm -f ${output_directory_full}*_weights.hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"${gmolabeler_path}/plots${data_folder}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd \"${gmolabeler_path}/plots/${data_folder}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -f ./plants_over_plates.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo ${gmolabeler_path}/output/${data_folder}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reporter in ${reporters[@]}; do\n",
    "    cp \"${gmolabeler_path}/output/${data_folder}/${reporter}/stats_with_sums_over_tissues.csv\" ./\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -f Rplots.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
